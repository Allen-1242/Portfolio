perplexity  = 50,     # good for 150k–200k points
theta       = 0.5,    # Barnes–Hut speed-up
verbose     = TRUE,
pca         = TRUE,
check_duplicates = FALSE
)
numeric_cols <- names(X)
X_scaled <- scale(X)
X <- X %>% drop_na()
temp <- train_df %>% filter(CERTHHSZ == 1)
X <- temp %>% select(FSEARN, FSUNEARN,
FSDEPDED, FSMEDDED, FSSLTEXP,
FSELDER, FSDIS)
# ── 2.  one-hot encode the two flags to numeric 0/1 cols ────────────────
X$FSELDER <- as.numeric(X$FSELDER)
X$FSDIS   <- as.numeric(X$FSDIS)
X
X <- X %>% drop_na()
library(dplyr)
X <- X %>% drop_na()
library(tidyr)
X <- X %>% drop_na()
# ── 3.  centre / scale numeric predictors (keeps t-SNE happy) ──────────
numeric_cols <- names(X)
X_scaled <- scale(X)
# ── 4.  run t-SNE (2-D) ────────────────────────────────────────────────
set.seed(123)
tsne_out <- Rtsne(
X_scaled,
dims        = 2,
perplexity  = 50,     # good for 150k–200k points
theta       = 0.5,    # Barnes–Hut speed-up
verbose     = TRUE,
pca         = TRUE,
check_duplicates = FALSE
)
# ── 5.  wrap into a ggplot, colour by approval label ────────────────────
tsne_df <- data.frame(
X      = tsne_out$Y[, 1],
Y      = tsne_out$Y[, 2],
group  = ifelse(temp$IS_APPROVED == 1, "Approved", "Denied")
)
ggplot(tsne_df, aes(X, Y, colour = group)) +
geom_point(alpha = 0.3, size = 0.6) +
scale_colour_manual(values = c("Approved" = "#1f78b4",
"Denied"   = "#e31a1c")) +
labs(title = "t-SNE of Maryland SNAP Positives vs. Synthetic Negatives",
x = "t-SNE 1", y = "t-SNE 2", colour = "Group") +
theme_minimal(base_size = 13)
tsne_df$reason <- temp$DENIAL_CODE[as.numeric(rownames(temp))]
ggplot(tsne_df, aes(X, Y, colour = reason)) +
geom_point(alpha = 0.4, size = 0.7) +
scale_colour_brewer(palette = "Set1") +
labs(title = "t-SNE by Denial Reason", x = "t-SNE 1", y = "t-SNE 2") +
theme_minimal(base_size = 13)
#Umap testing
library(umap)
umap_conf <- umap.defaults
umap_conf$n_neighbors <- 30   # neighborhood size
umap_conf$min_dist    <- 0.05  # spread / tightness
umap_out <- umap(X_scaled, config = umap_conf)
cols <- c("NA" = "grey50",
"EXCESS_GROSS" = "red",
"EXCESS_GROSS+EXCESS_NET" = "blue",
"EXCESS_GROSS+EXCESS_NET+SHELTER_CAP" = "forestgreen")
plot(umap_out$layout,
col = cols[train_df$DENIAL_CODE],
pch = 19, cex = 0.6,
xlab = "UMAP-1", ylab = "UMAP-2",
main = "UMAP embedding by denial reason")
legend("topright", legend = names(cols), col = cols, pch = 19)
#Counterfactual generation
library("counterfactuals")
library("iml")
library("randomForest")
library("mlr3")
library("mlr3learners")
#Improvements:
#1. We need to corrently fit the model instead of traning it on a wide variety of systems
#2. Counterfactual testing
set.seed(20210816)
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
library("counterfactuals")
library("iml")
library("randomForest")
library("mlr3")
library("mlr3learners")
set.seed(20210816)
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
train_df
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
train_df <- train_df %>% drop_na()
library(tidyr)
set.seed(20210816)
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
predictor = iml::Predictor$new(rf, type = "prob")
x_interest = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,"FSUNEARN","FSDIS" ,"FSELDER")][-1]
predictor$predict(x_interest)
nice_classif = NICEClassif$new(predictor, finish_early = FALSE, return_multiple  = TRUE)
nice_classif
colnames(data_cleaned_maryland)
keep_cols <- setdiff(names(data_cleaned_maryland),
names(counterfactual_data))
counterfactual_data
library(data.table)
library(TangledFeatures)
library(counterfactuals)
library(tidyr)
keep_cols
counterfactual_data <- cfactuals$data
cfactuals = nice_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
cfact<- 1999
cfactuals = nice_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
x_interest = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,"FSUNEARN","FSDIS" ,"FSELDER", "HOMELESS_DED")][-1]
predictor$predict(x_interest)
nice_classif = NICEClassif$new(predictor, finish_early = FALSE, return_multiple  = TRUE)
#Readding the dropped columns
colnames(data_cleaned_maryland)
keep_cols <- setdiff(names(data_cleaned_maryland),
names(counterfactual_data))
cfact<- 1999
cfactuals = nice_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
counterfactual_data <- cfactuals$data
counterfactual_data
keep_cols <- setdiff(names(data_cleaned_maryland),
names(counterfactual_data))
keep_cols
#Final testing
x_interest[cfact]
print(cfactuals)
x_interest[cfact]
print(cfactuals)
print(cfactuals)
x_interest[cfact]
print(cfactuals)
library(httr)
library(jsonlite)
library(httr)
library(jsonlite)
url <- "http://104.236.203.213:8000/llm"
input_text <- list(input = "What is SNAP eligibility?")
response <- POST(url, body = input_text, encode = "json")
response <- POST(url, body = input_text, encode = "json")
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "Explain SNAP eligibility."),
encode = "json"
)
cat(content(response)$response)
x_interest[cfact]
print(cfactuals)
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 3541
FSUNEARN: 0
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences.
"),
encode = "json"
)
cat(content(response)$response)
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 3541
FSUNEARN: 0
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences. Suggest ways to achieve this as well.
"),
encode = "json"
)
cat(content(response)$response)
MOC_classif = MOCClassif$new(predictor, finish_early = FALSE, return_multiple  = TRUE, fixed_features = c("FSEARN" ,"FSUNEARN"))
MOC_classif = MOCClassif$new(predictor, fixed_features = c("FSEARN" ,"FSUNEARN"))
cfactuals = MOC_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1), fixed_fea
)
cfactuals = MOC_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
cfactuals
x_interest[cfact]
print(cfactuals)
library(ggplot2)
library(dplyr)
fearn_range <- seq(min(train_df$FSEARN), max(train_df$FSEARN), length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED), max(train_df$FSDEPDED), length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "target"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
names(train_df)
data_cleaned_maryland
fearn_range <- seq(min(data_cleaned_maryland$FSEARN), max(data_cleaned_maryland$FSEARN), length.out = 100)
fdep_range <- seq(min(data_cleaned_maryland$FSDEPDED), max(data_cleaned_maryland$FSDEPDED), length.out = 100)
fearn_range <- seq(min(data_cleaned_maryland$FSEARN), max(data_cleaned_maryland$FSEARN), length.out = 100)
fdep_range <- seq(min(data_cleaned_maryland$FSDEPDED), max(data_cleaned_maryland$FSDEPDED), length.out = 100)
min(data_cleaned_maryland$FSDEPDED)
data_cleaned_maryland$FSDEPDED
train_df
train_df
fearn_range <- seq(min(train_df$FSEARN), max(train_df$FSEARN), length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED), max(train_df$FSDEPDED), length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
grid$pred <- predict(rf, newdata = grid, type = "response")
grid
original_point <- x_interest[1, ]
cf_point <- cfactuals[1, ]
original_point <- x_interest[1, ]
original_point
cfactuals[1, ]
cfactuals
cfactuals[1][1, ]
cfactuals
as.data.table(cfactuals)
cfactuals$data
clear
cfactuals$evaluate_set
cfactuals$desired
cfactuals$print
cfactuals$x_interest
cfactuals$desired
cfactuals$method
clear
cfactuals$X
cfactuals
cfactuals$Head
cfactuals$method
clear
cfactuals$evaluate_set
cfactuals$evaluate
cfactuals$predict
cfactuals$print
cfactuals
cfactuals$evaluate_set
cfactuals$data
cfactuals$data[1]
cf_point <- cfactuals[1]
cfactuals[1]
cfactuals[,1]
cfactuals[1,]
cfactuals$data[1,]
cf_point <- cfactuals$data[1,]
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
clear
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
rlang::last_trace()
grid
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
grid$pred
grid$pred <- as.numeric(as.character(grid$pred))
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
fearn_range <- seq(min(your_data$FSEARN) * 0.9, max(your_data$FSEARN) * 1.1, length.out = 100)
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
# Step 3: Predict probabilities
grid$pred <- predict(rf, newdata = grid, type = "response")
# Step 4: Add original and counterfactual points
original_point <- x_interest[1, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
# Step 1: Create a grid over FSEARN and FSDEPDED
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
grid$pred <- predict(rf, newdata = grid, type = "response")
original_point <- x_interest[1, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
grid$pred <- as.numeric(as.character(grid$pred))
# Step 4: Add original and counterfactual points
original_point <- x_interest[1, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
predict(train_df, newdata = original_point, type = "prob")[, 2]
cfactuals$data[1,]
x_interest
x_interest[1, ]
x_interest[1999, ]
x_interest
x_interest[cfact]
# Step 1: Create a grid over FSEARN and FSDEPDED
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
predict(train_df, newdata = original_point, type = "prob")[, 2]
# Step 1: Create a grid over FSEARN and FSDEPDED
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
# Step 3: Predict probabilities
grid$pred <- predict(rf, newdata = grid, type = "response")
grid$pred <- as.numeric(as.character(grid$pred))
# Step 4: Add original and counterfactual points
original_point <- x_interest[1999, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
cfactuals$data
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 3541
FSUNEARN: 0
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences. Suggest ways to achieve this as well.
"),
encode = "json"
)
cat(content(response)$response)
x_interest[cfact]
print(cfactuals)
cfactuals$data
cf_point
cf_point <- cfactuals$data[3,]
cf_point
cf_point <- cfactuals$data[7,]
cf_point
print(cfactuals)
cfactuals$data
cfactuals$data[9,]
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 7
FSDEPDED: 310.7992
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences. Suggest ways to achieve this as well.
"),
encode = "json"
)
cat(content(response)$response)
clear
cls
git
clear
git
library(boot)
usethis::use_logo("man/figures/logo.png")
ls
pwd
usethis::use_logo("man/figures/logo.png")
