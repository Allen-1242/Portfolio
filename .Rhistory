legend("topright", legend = names(cols), col = cols, pch = 19)
#Counterfactual generation
library("counterfactuals")
library("iml")
library("randomForest")
library("mlr3")
library("mlr3learners")
#Improvements:
#1. We need to corrently fit the model instead of traning it on a wide variety of systems
#2. Counterfactual testing
set.seed(20210816)
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
library("counterfactuals")
library("iml")
library("randomForest")
library("mlr3")
library("mlr3learners")
set.seed(20210816)
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
train_df
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
train_df <- train_df %>% drop_na()
library(tidyr)
set.seed(20210816)
train_df$IS_APPROVED <- as.factor(train_df$IS_APPROVED)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
predictor = iml::Predictor$new(rf, type = "prob")
x_interest = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,"FSUNEARN","FSDIS" ,"FSELDER")][-1]
predictor$predict(x_interest)
nice_classif = NICEClassif$new(predictor, finish_early = FALSE, return_multiple  = TRUE)
nice_classif
colnames(data_cleaned_maryland)
keep_cols <- setdiff(names(data_cleaned_maryland),
names(counterfactual_data))
counterfactual_data
library(data.table)
library(TangledFeatures)
library(counterfactuals)
library(tidyr)
keep_cols
counterfactual_data <- cfactuals$data
cfactuals = nice_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
cfact<- 1999
cfactuals = nice_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
rf = randomForest::randomForest(IS_APPROVED ~ ., data = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,  "FSUNEARN"   ,"FSDIS" ,"FSELDER", "HOMELESS_DED", "IS_APPROVED")][-1], importance=TRUE)
x_interest = train_df[,c("CERTHHSZ","FSDEPDED","FSMEDDED","FSSLTEXP" ,"FSEARN" ,"FSUNEARN","FSDIS" ,"FSELDER", "HOMELESS_DED")][-1]
predictor$predict(x_interest)
nice_classif = NICEClassif$new(predictor, finish_early = FALSE, return_multiple  = TRUE)
#Readding the dropped columns
colnames(data_cleaned_maryland)
keep_cols <- setdiff(names(data_cleaned_maryland),
names(counterfactual_data))
cfact<- 1999
cfactuals = nice_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
counterfactual_data <- cfactuals$data
counterfactual_data
keep_cols <- setdiff(names(data_cleaned_maryland),
names(counterfactual_data))
keep_cols
#Final testing
x_interest[cfact]
print(cfactuals)
x_interest[cfact]
print(cfactuals)
print(cfactuals)
x_interest[cfact]
print(cfactuals)
library(httr)
library(jsonlite)
library(httr)
library(jsonlite)
url <- "http://104.236.203.213:8000/llm"
input_text <- list(input = "What is SNAP eligibility?")
response <- POST(url, body = input_text, encode = "json")
response <- POST(url, body = input_text, encode = "json")
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "Explain SNAP eligibility."),
encode = "json"
)
cat(content(response)$response)
x_interest[cfact]
print(cfactuals)
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 3541
FSUNEARN: 0
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences.
"),
encode = "json"
)
cat(content(response)$response)
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 3541
FSUNEARN: 0
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences. Suggest ways to achieve this as well.
"),
encode = "json"
)
cat(content(response)$response)
MOC_classif = MOCClassif$new(predictor, finish_early = FALSE, return_multiple  = TRUE, fixed_features = c("FSEARN" ,"FSUNEARN"))
MOC_classif = MOCClassif$new(predictor, fixed_features = c("FSEARN" ,"FSUNEARN"))
cfactuals = MOC_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1), fixed_fea
)
cfactuals = MOC_classif$find_counterfactuals(
x_interest[cfact], desired_class = '1', desired_prob = c(0.5, 1)
)
cfactuals
x_interest[cfact]
print(cfactuals)
library(ggplot2)
library(dplyr)
fearn_range <- seq(min(train_df$FSEARN), max(train_df$FSEARN), length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED), max(train_df$FSDEPDED), length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "target"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
names(train_df)
data_cleaned_maryland
fearn_range <- seq(min(data_cleaned_maryland$FSEARN), max(data_cleaned_maryland$FSEARN), length.out = 100)
fdep_range <- seq(min(data_cleaned_maryland$FSDEPDED), max(data_cleaned_maryland$FSDEPDED), length.out = 100)
fearn_range <- seq(min(data_cleaned_maryland$FSEARN), max(data_cleaned_maryland$FSEARN), length.out = 100)
fdep_range <- seq(min(data_cleaned_maryland$FSDEPDED), max(data_cleaned_maryland$FSDEPDED), length.out = 100)
min(data_cleaned_maryland$FSDEPDED)
data_cleaned_maryland$FSDEPDED
train_df
train_df
fearn_range <- seq(min(train_df$FSEARN), max(train_df$FSEARN), length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED), max(train_df$FSDEPDED), length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
grid$pred <- predict(rf, newdata = grid, type = "response")
grid
original_point <- x_interest[1, ]
cf_point <- cfactuals[1, ]
original_point <- x_interest[1, ]
original_point
cfactuals[1, ]
cfactuals
cfactuals[1][1, ]
cfactuals
as.data.table(cfactuals)
cfactuals$data
clear
cfactuals$evaluate_set
cfactuals$desired
cfactuals$print
cfactuals$x_interest
cfactuals$desired
cfactuals$method
clear
cfactuals$X
cfactuals
cfactuals$Head
cfactuals$method
clear
cfactuals$evaluate_set
cfactuals$evaluate
cfactuals$predict
cfactuals$print
cfactuals
cfactuals$evaluate_set
cfactuals$data
cfactuals$data[1]
cf_point <- cfactuals[1]
cfactuals[1]
cfactuals[,1]
cfactuals[1,]
cfactuals$data[1,]
cf_point <- cfactuals$data[1,]
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
clear
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
rlang::last_trace()
grid
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
grid$pred
grid$pred <- as.numeric(as.character(grid$pred))
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
fearn_range <- seq(min(your_data$FSEARN) * 0.9, max(your_data$FSEARN) * 1.1, length.out = 100)
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
# Step 3: Predict probabilities
grid$pred <- predict(rf, newdata = grid, type = "response")
# Step 4: Add original and counterfactual points
original_point <- x_interest[1, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
# Step 1: Create a grid over FSEARN and FSDEPDED
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
grid$pred <- predict(rf, newdata = grid, type = "response")
original_point <- x_interest[1, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
grid$pred <- as.numeric(as.character(grid$pred))
# Step 4: Add original and counterfactual points
original_point <- x_interest[1, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
predict(train_df, newdata = original_point, type = "prob")[, 2]
cfactuals$data[1,]
x_interest
x_interest[1, ]
x_interest[1999, ]
x_interest
x_interest[cfact]
# Step 1: Create a grid over FSEARN and FSDEPDED
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
predict(train_df, newdata = original_point, type = "prob")[, 2]
# Step 1: Create a grid over FSEARN and FSDEPDED
fearn_range <- seq(min(train_df$FSEARN) * 0.9, max(train_df$FSEARN) * 1.1, length.out = 100)
fdep_range <- seq(min(train_df$FSDEPDED) * 0.9, max(train_df$FSDEPDED) * 1.1, length.out = 100)
grid <- expand.grid(FSEARN = fearn_range, FSDEPDED = fdep_range)
# Step 2: Add median values for all other features
for (col in setdiff(names(train_df), c("FSEARN", "FSDEPDED", "IS_APPROVED"))) {
grid[[col]] <- median(train_df[[col]], na.rm = TRUE)
}
# Step 3: Predict probabilities
grid$pred <- predict(rf, newdata = grid, type = "response")
grid$pred <- as.numeric(as.character(grid$pred))
# Step 4: Add original and counterfactual points
original_point <- x_interest[1999, ]
cf_point <- cfactuals$data[1,]
# Step 5: Plot
ggplot(grid, aes(x = FSEARN, y = FSDEPDED)) +
geom_tile(aes(fill = pred), alpha = 0.7) +
geom_contour(aes(z = pred), breaks = 0.5, color = "black") +
geom_point(data = original_point, aes(x = FSEARN, y = FSDEPDED), color = "red", size = 3) +
geom_point(data = cf_point, aes(x = FSEARN, y = FSDEPDED), color = "green", size = 3) +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Decision Boundary with Original and Counterfactual",
fill = "P(class = 1)")
cfactuals$data
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 3541
FSUNEARN: 0
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences. Suggest ways to achieve this as well.
"),
encode = "json"
)
cat(content(response)$response)
x_interest[cfact]
print(cfactuals)
cfactuals$data
cf_point
cf_point <- cfactuals$data[3,]
cf_point
cf_point <- cfactuals$data[7,]
cf_point
print(cfactuals)
cfactuals$data
cfactuals$data[9,]
response <- POST(
url = "http://104.236.203.213:8000/llm",
body = list(input = "You are a policy assistant helping users understand what changes they need to make to become eligible for SNAP benefits.
Here is a user's current profile (factual):
CERTHHSZ: 4
FSDEPDED: 3844
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Here is the profile needed to become eligible (counterfactual):
CERTHHSZ: 7
FSDEPDED: 310.7992
FSMEDDED: 0
FSSLTEXP: 2000
FSEARN: 4698
FSUNEARN: 3287.5
FSDIS: 0
FSELDER: 0
HOMELESS_DED: 0
Please explain in plain language what this person needs to change to become eligible. Focus only on the differences. Suggest ways to achieve this as well.
"),
encode = "json"
)
cat(content(response)$response)
clear
cls
git
clear
git
library(boot)
usethis::use_logo("man/figures/logo.png")
ls
pwd
usethis::use_logo("man/figures/logo.png")
clear
install.packages("StructuralDecompose")
cls
clear
^L
L
library(StructuralDecompose)
data <- StructuralDecompose$Nile_dataset
data <- StructuralDecompose::Nile_dataset[,1]
data
matplot(data, type = 'l')
matplot(trend)
trend
decomposed
#decomposed
#decomposed
#decomposed
data <- ts(data = as.vector(t(data)), frequency = 12)
data
stl(data)
stl(data, s.window = 'periodic')
decomposed
decomposed
#decomposed
#seasonal <- decomposed$time.series[,1]
#trend <- decomposed$time.series[,2]
#remainder <- decomposed$time.series[,3]
z <- c(1,2,4)
#decomposed <- stl
#data
#decomposed <- stl(data, s.window = 'periodic')
#data
#decomposed <- stl(data, s.window = 'periodic')
stl(data, s.window = 'periodic')
data
data
#decomposed
data
detach("package:StructuralDecompose", unload = TRUE)
library(StructuralDecompose)
frequency = 12)
data
StructuralDecompose::Nile_dataset[,1]
data <- StructuralDecompose::Nile_dataset[,1]
data <- ts(data = as.vector(t(data)), frequency = 12)
#data
decomposed <- stl(data, s.window = 'periodic')
stl(data, s.window = 'periodic')
remainder <- decomposed$time.series[,3]
#stl(data, s.window = 'periodic')
seasonal <- decomposed$time.series[,1]
trend <- decomposed$time.series[,2]
seasonal
trend
AnomalyDetection(timeseries = StructuralDecompose::Nile_dataset[,1], breaks = c(4, 50, 80))
Anomalies <- AnomalyDetection(timeseries = StructuralDecompose::Nile_dataset[,1], breaks = c(4, 50, 80))$Anomalies
Anomalies
matplot(data, Anomalies)
library(StructuralDecompose)
z <- c(1,2,4)
library(StructuralDecompose)
z <- c(1,2,4)
data <- StructuralDecompose::Nile_dataset[,1]
data
data <- ts(data = as.vector(t(data)), frequency = 12)
#data
decomposed <- stl(data, s.window = 'periodic')
decomposed
decomposed
stl(data, s.window = 'periodic')
