---
title: "Welcome"
format:
  html:
    page-layout: full
---

Hi, I'm Allen Sunny. I am a masters student at the University of Maryland College Park.  I build human-centered AI systems and conduct research at the intersection of machine learning, public services, and digital accountability. I am currently finishing my masters thesis under the guidance of Professor [Ido Sivan-Sevilla](https://ischool.umd.edu/directory/ido-sivan-sevilla/). 

This site showcases my coursework, research papers, and links to my code.

---

## Read my current work:

- 📄 [Download My Resume (PDF)](papers/Resume.pdf)
- 📝 [Read My Blog on Substack](https://allensai.substack.com/)

---

## Projects and Papers

### Masters Thesis: Human-Centered AI for the Public Sector
A government-focused AI framework and prototype designed to support responsible deployment through case studies, human-centered design principles, and post-deployment evaluation.

- 📄 Thesis (in progress)
- 💻 Prototype (coming soon)


### Dark Pattern Analysis 
A browser extension that detects deceptive UX patterns on websites using DOM inspection and LLM-based classification.

- 📄 [Paper](papers/CMSC_839__Checkpoint4.pdf)
- 💻 [Code](https://github.com/Allen-1242/Dark_Patterns)


### RADAR: Retrieval-Augmented Data Analysis and Representation
RADAR is a RAG-powered system that uses LLaMA 3.1 8B to generate explainable data visualizations from natural language input, enabling users to intuitively explore and understand data.

- 📄 [Paper](papers/INST760.pdf)
- 💻 [Code](https://github.com/Allen-1242/Radar)


### Trust in Transparency: How Explainable AI Shapes User Perceptions
Uses interviews to explore how users emotionally respond to AI explanations. Reveals that trust depends not just on transparency, but also on reliability, clarity, and perceived agency.

- 📄 [Paper](papers/INST_808__User_AI_Research_Final-2.pdf)


### Explainability and Trust in AI: A Quantitative Approach
Examines how different types of AI explanations impact user trust through experiments and surveys. Finds that well-designed, context-sensitive explanations significantly improve perceived fairness and trust.

- 📄 [Paper](papers/INST_808__User_AI_Research.pdf)


---

## Open Source 
<h2 style="font-weight: bold; font-size: 1.25em;">Oxford AI Monitoring System</h2>

- [Monitoring System](https://github.com/Allen-1242/Oxford_AI_Monitoring)

Automatic web scrapper that tracks the adoption of foundation models by companies

<h2 style="font-weight: bold; font-size: 1.25em;">TangledFeatures</h2>

- [TangledFeatures](https://allen-1242.github.io/TangledFeatures/)
- [TangledFeatures Documentation](https://cloud.r-project.org/web/packages/TangledFeatures/TangledFeatures.pdf)

TangledFeatures is a feature selection algorithm that extracts features in highly correlated spaces. The extracted features are meant to be fed into simple explainable models such as linear or logistic regressions. This R package is useful in the field of explainable modelling as a way to understand variable behavior.

<h2 style="font-weight: bold; font-size: 1.25em;">StructuralDecompose</h2>

- [StructuralDecompose](https://allen-1242.github.io/StructuralDecompose/)
- [StructuralDecompose Documentation](https://cloud.r-project.org/web/packages/StructuralDecompose/StructuralDecompose.pdf)

This R package explains the behavior of a time series by decomposing it into its trend, seasonality and residuals. It is built to perform very well in the presence of significant level shifts. 


---



## About This Site

Built using [Quarto](https://quarto.org), hosted on [GitHub Pages](https://pages.github.com), and always evolving.
